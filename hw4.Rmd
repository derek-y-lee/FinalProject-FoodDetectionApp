#Sean Campeau | Ellen Do | Derek Lee
###Homework 4 | Biostatistics M280

&nbsp;
&nbsp;
&nbsp;

##Q1: Learn by Doing
&nbsp;
#####In this problem, Derek chose the model while Ellen & Sean jointly tested the model and changed the parameters.
&nbsp;
#####We reproduced the results in the blog using the given code. First, install necessary packages:
&nbsp;
```{R}
# Keras + TensorFlow and it's dependencies
install.packages("keras", repos = "http://cran.us.r-project.org")
library(keras)
install_keras()

# Tidyverse (readr, ggplot2, etc.)
install.packages("tidyverse", repos = "http://cran.us.r-project.org")

# Packages for sequence logos and peptides
devtools::install_github("omarwagih/ggseqlogo")
devtools::install_github("leonjessen/PepTools")
```
&nbsp;
#####Start:
&nbsp;
```{R}
library(keras)
library(tidyverse)
library(PepTools)

# reading in data
pep_file <- get_file(
  "ran_peps_netMHCpan40_predicted_A0201_reduced_cleaned_balanced.tsv", 
  origin = "https://git.io/vb3Xa"
) 
pep_dat <- read_tsv(file = pep_file)

pep_dat %>% group_by(label_chr, data_type) %>% summarise(n = n())

pep_dat %>% filter(label_chr=='SB') %>% head(1) %>% pull(peptide) %>% pep_plot_images

str(pep_encode(c("LLTDAQRIV", "LLTDAQRIV")))

# turning into arrays
x_train <- pep_dat %>% filter(data_type == 'train') %>% pull(peptide)   %>% pep_encode
y_train <- pep_dat %>% filter(data_type == 'train') %>% pull(label_num) %>% array
x_test  <- pep_dat %>% filter(data_type == 'test')  %>% pull(peptide)   %>% pep_encode
y_test  <- pep_dat %>% filter(data_type == 'test')  %>% pull(label_num) %>% array

# creating final arrays to feed into model
x_train <- array_reshape(x_train, c(nrow(x_train), 9 * 20))
x_test  <- array_reshape(x_test,  c(nrow(x_test), 9 * 20))
y_train <- to_categorical(y_train, num_classes = 3)
y_test  <- to_categorical(y_test,  num_classes = 3)

# defining model
model <- keras_model_sequential() %>% 
  layer_dense(units  = 180, activation = 'relu', input_shape = 180) %>% 
  layer_dropout(rate = 0.4) %>% 
  layer_dense(units  = 90, activation  = 'relu') %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units  = 3, activation   = 'softmax')

# training and evaluating model
model %>% compile(
  loss      = 'categorical_crossentropy',
  optimizer = optimizer_rmsprop(),
  metrics   = c('accuracy')
)

# compiling model
history = model %>% fit(
  x_train, y_train, 
  epochs = 150, 
  batch_size = 50, 
  validation_split = 0.2
)

plot(history)
```
&nbsp;
#####For 2nd part of question 1
&nbsp;
```{r}
# defining model
model2 <- keras_model_sequential() %>% 
  layer_dense(units  = 180, activation = 'relu', input_shape = 180) %>% 
  layer_dropout(rate = 0.4) %>% 
  layer_dense(units  = 90, activation  = 'relu') %>%
  layer_dropout(rate = 0.3) %>%
  layer_dense(units  = 3, activation   = 'softmax')

# training and evaluating model
model2 %>% compile(
  loss      = 'categorical_crossentropy',
  optimizer = optimizer_rmsprop(lr=0.0005, rho=0.9, decay=0.0),
  metrics   = c('accuracy')
)

# compiling model
history2 = model2 %>% fit(
  x_train, y_train, 
  epochs = 150, 
  batch_size = 50, 
  validation_split = 0.2
)

plot(history2)
```
&nbsp;
## Q2 Deep learning on smart phone

Professor May Wang in Department of Community Health Sciences (CHS) studies obesity in children and intervention strategies to prevent obesity. She asked me whether it is possible to develop an app such that a user takes a photo of a meal and the app will recognize and record the type of food (pizza, mac and cheese, burger, ...). 

Your job: produce a prototype app for iPhone or Android smart phone. 

Resources:  
1. There are plenty of tutorials and YouTube clips on making apps for iPhone or Android.  
2. Google's [Cloud Vision API](https://cloud.google.com/vision/) may supply an easy solution. 